{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407907de",
   "metadata": {},
   "source": [
    "# 12.0. DEPLOY MODEL TO PRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca21b10",
   "metadata": {},
   "source": [
    "## 12.1. Rossmann Class\n",
    "\n",
    "The Rossmann class performs all the cleaning, transformation and encoding of the data that will be received via the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2edf7d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:26:50.483697Z",
     "start_time": "2022-07-09T00:26:50.451540Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "class Rossmann( object ):\n",
    "    def __init__( self ):\n",
    "        self.home_path = sys.path[0]+'/repos/parameters/'\n",
    "        self.competition_distance_scaler   = pickle.load( open( self.home_path + 'competition_distance_scaler.pkl', 'rb') )\n",
    "        self.competition_time_month_scaler = pickle.load( open( self.home_path + 'competition_time_month_scaler.pkl', 'rb') )\n",
    "        self.promo_time_week_scaler        = pickle.load( open( self.home_path + 'promo_time_week_scaler.pkl', 'rb') )\n",
    "        self.year_scaler                   = pickle.load( open( self.home_path + 'year_scaler.pkl', 'rb') )\n",
    "        self.store_type_scaler             = pickle.load( open( self.home_path + 'store_type_scaler.pkl', 'rb') )\n",
    "        \n",
    "    def data_cleaning( self, df1 ):\n",
    "        ## 1.1. Rename Columns\n",
    "        df1.columns = ['store', 'day_of_week', 'date', 'sales', 'customers', 'open', 'promo', 'state_holiday', 'school_holiday', 'store_type', \n",
    "        'assortment', 'competition_distance', 'competition_open_since_month', 'competition_open_since_year', 'promo2', 'promo2_since_week', \n",
    "        'promo2_since_year', 'promo_interval']\n",
    "        \n",
    "        ## 1.3. Data Types\n",
    "        df1['date'] = pd.to_datetime( df1['date'] )\n",
    "        \n",
    "        ## 1.5. Fillout NA\n",
    "        #competition_distance        \n",
    "        df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 200000.0 if math.isnan( x ) else x )\n",
    "        #competition_open_since_month\n",
    "        df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if \n",
    "                                                        math.isnan( x['competition_open_since_month'] ) else\n",
    "                                                        x['competition_open_since_month'], axis=1 )\n",
    "        \n",
    "        \n",
    "        #competition_open_since_year\n",
    "        df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else\n",
    "                                                       x['competition_open_since_year'], axis=1 )\n",
    "\n",
    "        #promo2_since_week\n",
    "        df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
    "\n",
    "        #promo2_since_year\n",
    "        df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
    "\n",
    "        #promo_interval\n",
    "        month_map = {1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Apr', 5: 'May', 6:\n",
    "                     'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "        df1['promo_interval'].fillna(0, inplace=True )\n",
    "        df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
    "        df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 \n",
    "                                                                     else 1 if x['month_map'] in x['promo_interval'].split( ',' ) \n",
    "                                                                     else 0, axis=1 )\n",
    "\n",
    "        ## 1.6. Change Data Types\n",
    "        # competiton\n",
    "        df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int )\n",
    "        df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int )\n",
    "\n",
    "        # promo2\n",
    "        df1['promo2_since_week'] = df1['promo2_since_week'].astype( int )\n",
    "        df1['promo2_since_year'] = df1['promo2_since_year'].astype( int )\n",
    "        \n",
    "        return df1\n",
    "        \n",
    "    def feature_engineering( self, df2 ):\n",
    "\n",
    "        # year\n",
    "        df2['year'] = df2['date'].dt.year\n",
    "\n",
    "        # month\n",
    "        df2['month'] = df2['date'].dt.month\n",
    "        \n",
    "        # day\n",
    "        df2['day'] = df2['date'].dt.day\n",
    "\n",
    "        # week of year\n",
    "        df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "\n",
    "        # year week\n",
    "        df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )\n",
    "\n",
    "        # competition since\n",
    "        df2['competition_since'] = df2.apply( lambda x: datetime.datetime(year=x['competition_open_since_year'],month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "        df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "        # promo since\n",
    "        df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "        df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "        df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "        # assortment\n",
    "        df2['assortment'] = df2['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "\n",
    "        # state holiday\n",
    "        df2['state_holiday'] = df2['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' \n",
    "                                                          else 'christmas' if x == 'c' else 'regular_day' )\n",
    "\n",
    "        # 3.0. PASSO 03 - FILTRAGEM DE VARI√ÅVEIS\n",
    "        ## 3.1. Filtragem das Linhas\n",
    "        df2 = df2[df2['open'] != 0]\n",
    "\n",
    "        ## 3.2. Selecao das Colunas\n",
    "        cols_drop = ['open', 'promo_interval', 'month_map']\n",
    "        df2 = df2.drop( cols_drop, axis=1 )\n",
    "        \n",
    "        return df2\n",
    "\n",
    "    def data_preparation( self, df5 ):\n",
    "        ## 5.2. Rescaling\n",
    "        # competition distance\n",
    "        df5['competition_distance'] = self.competition_distance_scaler.transform( df5[['competition_distance']].values )\n",
    "\n",
    "        # competition time month\n",
    "        df5['competition_time_month'] = self.competition_time_month_scaler.transform( df5[['competition_time_month']].values )\n",
    "\n",
    "        # promo time week\n",
    "        df5['promo_time_week'] = self.promo_time_week_scaler.transform(df5[['promo_time_week']].values )\n",
    "\n",
    "        # year\n",
    "        df5['year'] = self.year_scaler.transform( df5[['year']].values )\n",
    "\n",
    "        ### 5.3.1. Encoding\n",
    "        # state_holiday - One Hot Encoding\n",
    "        df5 = pd.get_dummies( df5, prefix=['state_holiday'],columns=['state_holiday'] )\n",
    "\n",
    "        # store_type - Label Encoding\n",
    "        df5['store_type'] = self.store_type_scaler.transform( df5['store_type'] )\n",
    "\n",
    "        # assortment - Ordinal Encoding\n",
    "        assortment_dict = {'basic': 1, 'extra': 2, 'extended': 3}\n",
    "        df5['assortment'] = df5['assortment'].map( assortment_dict )\n",
    "\n",
    "        ### 5.3.3. Nature Transformation\n",
    "        # day of week\n",
    "        df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "        df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x * ( 2. * np.pi/7 ) ) )\n",
    "\n",
    "        # month\n",
    "        df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "        df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x * ( 2. * np.pi/12 ) ) )\n",
    "\n",
    "        # day\n",
    "        df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/ 30 ) ) )\n",
    "        df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x * ( 2. * np.pi/ 30 ) ) )\n",
    "\n",
    "        # week of year\n",
    "        df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )\n",
    "        df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x * ( 2. * np.pi/52 ) ) )\n",
    "        cols_selected = [ 'store', 'promo', 'store_type', 'assortment', 'competition_distance', 'competition_open_since_month',\n",
    "        'competition_open_since_year', 'promo2', 'promo2_since_week', 'promo2_since_year', 'competition_time_month', 'promo_time_week',\n",
    "        'day_of_week_sin', 'day_of_week_cos', 'month_sin', 'month_cos', 'day_sin', 'day_cos', 'week_of_year_sin', 'week_of_year_cos']\n",
    "\n",
    "        return df5[ cols_selected ]\n",
    "\n",
    "    def get_prediction( self, model, original_data, test_data ):\n",
    "        # prediction\n",
    "        pred = model.predict( test_data )\n",
    "        \n",
    "        # join pred into the original data\n",
    "        original_data['prediction'] = np.expm1( pred )\n",
    "        \n",
    "        return original_data.to_json( orient='records', date_format='iso' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d079850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:16:13.766679Z",
     "start_time": "2022-07-09T00:16:13.758930Z"
    }
   },
   "source": [
    "## 12.2 API Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from flask import Flask, request, Response\n",
    "#from rossmann.Rossmann import Rossmann\n",
    "\n",
    "# loading model\n",
    "model = pickle.load( open( '/repos/model/model_xgb.pkl', 'rb') )\n",
    "\n",
    "# initialize API\n",
    "app = Flask( __name__ )\n",
    "\n",
    "@app.route( '/rossmann/predict', methods=['POST'] )\n",
    "\n",
    "def rossmann_predict():\n",
    "    test_json = request.get_json()\n",
    "    \n",
    "    if test_json: # there is data\n",
    "        \n",
    "        if isinstance( test_json, dict ): # unique example\n",
    "            test_raw = pd.DataFrame( test_json, index=[0] )\n",
    "        \n",
    "        else: # multiple example\n",
    "            test_raw = pd.DataFrame( test_json, columns=test_json[0].keys() )\n",
    "\n",
    "        # Instantiate Rossmann class\n",
    "        pipeline = Rossmann()\n",
    "        \n",
    "        # data cleaning\n",
    "        df1 = pipeline.data_cleaning( test_raw )\n",
    "        \n",
    "        # feature engineering\n",
    "        df2 = pipeline.feature_engineering( df1 )\n",
    "        \n",
    "        # data preparation\n",
    "        df3 = pipeline.data_preparation( df2 )\n",
    "        \n",
    "        # prediction\n",
    "        df_response = pipeline.get_prediction( model, test_raw, df3 )\n",
    "        \n",
    "        return df_response\n",
    "        \n",
    "    else:\n",
    "        return Response( '{}', status=200, mimetype='application/json' )\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run( '0.0.0.0' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb1f4ff",
   "metadata": {},
   "source": [
    "## 12.3 API Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8364a077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\projects\\rossmann_store_sales_prediction\n"
     ]
    }
   ],
   "source": [
    "# loading test dataset\n",
    "import pandas\n",
    "import sys\n",
    "import pandas as pd\n",
    "print(sys.path[0])\n",
    "df10 = pd.read_csv( sys.path[0]+'/repos/datasets/test.csv')\n",
    "df_store_raw = pd.read_csv( sys.path[0]+'/repos/datasets/store.csv', low_memory=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7188b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge test dataset + store\n",
    "df_test = pd.merge( df10, df_store_raw, how='left', on='Store' )\n",
    "\n",
    "# choose store for prediction\n",
    "df_test = df_test[df_test['Store'].isin( [20, 23, 22] )]\n",
    "\n",
    "# remove closed days\n",
    "df_test = df_test[df_test['Open'] != 0]\n",
    "df_test = df_test[~df_test['Open'].isnull()]\n",
    "df_test = df_test.drop( 'Id', axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d8f9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Dataframe to json\n",
    "import json\n",
    "data = json.dumps( df_test.to_dict( orient='records' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef3c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Call\n",
    "url = 'http://0.0.0.0:5000/rossmann/predict'\n",
    "import requests\n",
    "#url = 'https://sales-forecast-rossmann.herokuapp.com/rossmann/predict'\n",
    "header = {'Content-type': 'application/json' }\n",
    "data = data\n",
    "\n",
    "r = requests.post( url, data=data, headers=header )\n",
    "print( 'Status Code {}'.format( r.status_code ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame( r.json(), columns=r.json()[0].keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d1[['store', 'prediction']].groupby( 'store' ).sum().reset_index()\n",
    "\n",
    "for i in range( len( d2 ) ):\n",
    "    print( 'Store Number {} will sell R${:,.2f} in the next 6 weeks'.format(\n",
    "        d2.loc[i, 'store'],\n",
    "        d2.loc[i, 'prediction'] ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv-rossmann': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3344ce4af773815b968134d3746d8e80563dbd0ca1d8485184264ba73e9c4098"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
